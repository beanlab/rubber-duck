import asyncio
from pathlib import Path
import json
import yaml

import markdowndata
# TODO ask: step functions?
from quest import step, queue

from functools import reduce
import operator

from ..gen_ai.gen_ai import Agent, AIClient
from ..utils.config_types import DuckContext, AssignmentFeedbackSettings, Gradable
from ..utils.logger import duck_logger
from ..utils.protocols import Message

ASSIGNMENT_NAME =  str
SECTION = str
SECTION_NAME = str
RUBRIC_ITEM = str
REPORT_SECTION = str
FEEDBACK = str

class AssignmentFeedbackWorkflow:
    def __init__(self,
                 name: str,
                 send_message,
                 settings: AssignmentFeedbackSettings,
                 single_rubric_item_grader: Agent,
                 project_scanner_agent: Agent,
                 ai_client: AIClient,
                 read_url
                 ):
        self.name = name
        self._send_message = send_message
        self._settings = settings
        self._single_rubric_item_grader = single_rubric_item_grader
        self._project_scanner_agent = project_scanner_agent
        self._ai_client = ai_client
        self.read_url = read_url

        self._assignments_rubrics: dict[ASSIGNMENT_NAME: dict[SECTION: any]] = {}
        self._populate_assignments_rubrics()

    async def __call__(self, context: DuckContext):
        """
        Assumptions:
        - The project name is included in the first level 1 header in the document
        - Every header in the yaml rubric has a corresponding header in the md report
        - assumes matching pieces with the rubric
        """
        # TODO consider give another chance if they uploaded the wrong report?
        # get the broader workflow working and then can clean up specific assumptions
        # document the assumptions for this -- single header line -- `#`
        # fix the rubrics so the headers line up
        # clean everything up and see how clean the code is

        # Send an initial message
        await self._send_message(context.thread_id, self._settings.get("initial_message", "Content generated by AI may not be correct"))

        # Tell the user the supported assignments
        supported_assignments = ' '.join(self._assignments_rubrics.keys())
        await self._send_message(context.thread_id, f"The supported assignments for grading are {supported_assignments}")

        # Get the report contents from the user
        report_contents = await self._get_report_contents(context)

        if report_contents is None:
            return

        # Get the project name associated with the report
        project_name = await self._get_project_name_from_report(context, report_contents)

        # break up the report into very small pieces to grade with the associated rubric item
        tasks = [
            asyncio.create_task(self.single_item_ai_grader(context, piece_name, report_section, rubric_item))
            for piece_name, rubric_item, report_section in
            self._flatten_report_and_rubric_items(report_contents, self._assignments_rubrics[project_name])
        ]

        # wait for the responses of all the items
        graded_items: list[tuple[list[SECTION_NAME], RUBRIC_ITEM, FEEDBACK]] = await asyncio.gather(*tasks)

        # format for the user to read
        formatted_graded_items = self._format_graded_items(graded_items)

        await self._send_message(context.thread_id, formatted_graded_items)

    def _flatten_report_and_rubric_items(self, report_contents, rubric) -> list[tuple[list[SECTION_NAME], RUBRIC_ITEM, REPORT_SECTION]]:
        report = markdowndata.loads(report_contents)
        report_sections = report[list(report.keys())[0]]

        def helper_func(name, rubric_section, report_section):
            for section_name in rubric_section.keys():
                name.append(section_name)
                if isinstance(rubric_section[section_name], dict):
                    yield from helper_func(name, rubric_section[section_name], report_section[section_name])
                elif isinstance(rubric_section[section_name], list):
                    for section_item in rubric_section[section_name]:
                        print(name, section_item)
                        yield name[::], section_item, report_section[section_name]
                name.pop(-1)

        flattened = list(helper_func([], rubric, report_sections))
        return flattened

    def _format_graded_items(self, flattened_dict):
        result = self._unflatten_dictionary(flattened_dict)
        return yaml.dump(result, default_flow_style=False)

        # emoji = ':white_check_mark:' if item['satisfactory'] else ':x:'
        # # justification = '' if item['satisfactory'] else item['justification']
        # justification = item['justification']
        # feedback = f'{emoji} **{item["rubric_item"]}** - {justification}'
        # items.append(feedback)


    def get_nested(self, d, keys):
        return reduce(operator.getitem, keys, d)

    def set_nested(self, d, keys, value):
        *prefix, last = keys
        parent = reduce(lambda acc, k: acc.setdefault(k, {}), prefix, d)
        parent[last] = value

    def _unflatten_dictionary(self, results):
        unflattened = {}
        # for keys, rubric_item, graded_result in results:
        #     for key in keys[:-1]:
        #         if key not in unflattened:
        #             unflattened[key] = {}
        #         unflattened = unflattened[key]

        for keys, rubric_item, graded_result in results:
            self.set_nested(unflattened, keys, (rubric_item, graded_result))
        return unflattened

    def _get_rubric_content(self, assignment: Gradable):
        if 'rubric_path' in assignment:
            instructions = Path(assignment['rubric_path']).read_text(encoding="utf-8")
        else:
            raise ValueError(f"You must provide an 'rubric_path' for {assignment['name']}")
        return instructions

    def _populate_assignments_rubrics(self):
        for assignment in self._settings["gradable_assignments"]:
            raw_rubric_content = self._get_rubric_content(assignment)
            rubric_content = yaml.safe_load(raw_rubric_content)
            self._assignments_rubrics[assignment["name"]] = rubric_content

    def _get_project_name_directly_from_report(self, report_contents, valid_project_names):
        try:
            report_contents = markdowndata.loads(report_contents)
            top_headers = report_contents.keys()
            for header in top_headers:
                if header in valid_project_names:
                    return header
            return None
        except Exception as e:
            return None

    async def _get_project_name_using_agent(self, context, report_contents, valid_project_names):
        input = {
            'report_contents': report_contents,
            'valid_projects_names': valid_project_names
        }

        response = await self._ai_client.run_agent(context, self._project_scanner_agent, str(input))
        response = json.loads(response)  # returns structured output as specified in the config
        project = response["project_name"]

        if not project in valid_project_names:
            raise Exception(f"Invalid project name {project}")

        return project


    async def _get_project_name_from_report(self, context, report_contents):
        """
        report_contents is dictionary from mdd that contains the report contents
        The first header is assumed to be the name of the project
        returns the report name that matches
        """
        valid_project_names = [assignment["name"] for assignment in self._settings['gradable_assignments']]

        # Try to get the project name without relying on an agent first
        if project_name := self._get_project_name_directly_from_report(report_contents, valid_project_names):
            return project_name
        else:
            return self._get_project_name_using_agent(context, report_contents, valid_project_names)


    async def _get_report_contents(self, context):
        try:
            await self._send_message(context.thread_id, "Please upload your md report.")
            while True:
                response = await self._wait_for_message(context.timeout)
                attachments = response.get("files", [])
                md_attachments = [attachment for attachment in attachments if "md" in attachment["filename"]]

                if not md_attachments:
                    await self._send_message(context.thread_id, "No md files were uploaded. Please upload your md report: ")
                    continue

                file_contents = "\n".join([await self.read_url(attachment['url']) for attachment in md_attachments])
                return file_contents

        except Exception as e:
            duck_logger.warning(f"Exception: {e}")
            await self._send_message(context.thread_id, "Something went wrong.")


    # TODO unduplicate function from registration workflow?
    async def _wait_for_message(self, timeout=300) -> Message | None:
        async with queue('messages', None) as messages:
            try:
                message: Message = await asyncio.wait_for(messages.get(), timeout)
                return message
            except asyncio.TimeoutError:  # Close the thread if the conversation has closed
                return None

    async def single_item_ai_grader(self, context, piece_name, report_section, rubric_item):
        input = {"report_contents": report_section,
                 "rubric_item": rubric_item}
        raw_response = await self._ai_client.run_agent(context, self._single_rubric_item_grader, str(input))
        result = json.loads(raw_response)
        return piece_name, result


    # # TODO remove me v v v v v v
    # async def grade(current_section, rubric_items, report_section, per_rubric_item_grading=True):
    #     for rubric_item in rubric_items:
    #         yield curr_section, rubric_item, report_section
    #
    #     if per_rubric_item_grading:
    #         all_rubric_item_responses = []
    #         for rubric_item in rubric_items:
    #             raw_response = await self.single_item_ai_grader(context, report_section, rubric_item)
    #             formatted_response = json.loads(raw_response)
    #             all_rubric_item_responses.append(formatted_response)
    #     else:  # per section item grading
    #         try:
    #             ai_grader_response = await self.ai_grader(context, report_section, rubric_items)
    #             all_rubric_item_responses = json.loads(ai_grader_response)['results']
    #         except Exception as e:
    #             duck_logger.warning(e)
    #             return ai_grader_response
    #
    #     items = []
    #     for item in all_rubric_item_responses:
    #
    #     # TODO consider creating a report indicating which sections and rubric items were passed in for each call to grade
    #     return items
    #

    # async def get_feedback(self, context, report_section, section_rubric):
    #
    #     async def grader_helper(position, rubric, report_piece):
    #         if isinstance(rubric, list):
    #             curr_feedback_items = []
    #             rubric_items = []
    #             for i in rubric:
    #                 if isinstance(i, dict):
    #                     feedback = await grader_helper(i, report_piece)
    #                     curr_feedback_items.append(feedback)
    #                 else:
    #                     rubric_items.append(i)
    #
    #             if isinstance(report_piece, dict) and "content" in report_piece:
    #                 report_piece = report_piece["content"]
    #             if rubric_items:
    #                 feedback = await grade(rubric_items, report_piece)
    #                 feedback = [feedback]
    #             else:
    #                 feedback = []
    #             curr_feedback_items = feedback + curr_feedback_items
    #             return curr_feedback_items
    #
    #         elif isinstance(rubric, dict):
    #             curr_feedback_items = {}
    #             for key, value in rubric.items():
    #                 if key not in report_piece:
    #                     raise Exception(f"{key} missing from report")
    #                 feedback = await grader_helper(value, report_piece[key])
    #                 curr_feedback_items[key] = feedback
    #             return curr_feedback_items
    #         else:
    #             raise ValueError(f"Unexpected type of {type(rubric)}. Not a dictionary or a list ")
    #
    #     all_feedback_as_dict = await grader_helper(section_rubric, report_section)
    #
    #     feedback_str = yaml.dump(all_feedback_as_dict, sort_keys=False, width=10 ** 9, default_style=None)
    #     return feedback_str
    #
    # def _find_key(self, d, target):
    #     if target in d:
    #         return d[target]
    #
    #     for k, v in d.items():
    #         if isinstance(v, dict):
    #             result = self._find_key(v, target)
    #             if result is not None:
    #                 return result
    #     return None
    #
    # def _get_report_section(self, report_contents: str, section):
    #     data = markdowndata.loads(report_contents)
    #     section_contents = self._find_key(data, section)
    #
    #     if section_contents is None:
    #         return None
    #
    #     return section_contents
